<!doctype html>
<html lang="en" class="no-js">

<head>
    <!-- Jekyll Ideal Image Slider Include -->
    <!-- https://github.com/jekylltools/jekyll-ideal-image-slider-include -->
    <!-- v1.8 -->
    <meta charset="utf-8"> <!-- begin SEO -->
    <title>QV-Pipe Dataset - VideoPipe</title>
    <meta property="og:locale" content="en-US">
    <meta property="og:site_name" content="VideoPipe">
    <meta property="og:title" content="FineAction Dataset">
    <link rel="canonical" href="index.html">
    <meta property="og:url" content="https://videopipe.github.io/fineaction/">
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "Person",
            "name": "VideoPipe",
            "url": "https://videopipe.github.io",
            "sameAs": null
        }
    </script> <!-- end SEO -->
    <link href="../feed.xml" type="application/atom+xml" rel="alternate" title="VideoPipe Feed">
    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script>
        document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script> <!-- For all browsers -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <meta http-equiv="cleartype" content="on"> <!-- start custom head snippets -->
    <!-- <link rel="apple-touch-icon" sizes="57x57" href="https://videopipe.github.io/images/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="https://videopipe.github.io/images/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="https://videopipe.github.io/images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="https://videopipe.github.io/images/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114"
        href="https://videopipe.github.io/images/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120"
        href="https://videopipe.github.io/images/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144"
        href="https://videopipe.github.io/images/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152"
        href="https://videopipe.github.io/images/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180"
        href="https://videopipe.github.io/images/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="../images/favicon-32x32.png" sizes="32x32"> -->
    <!-- <link rel="icon" type="image/png" href="https://videopipe.github.io/images/android-chrome-192x192.png"
        sizes="192x192"> -->
    <link rel="icon" type="image/png" href="../images/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="../images/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="../images/manifest.json">
    <link rel="mask-icon" href="../images/safari-pinned-tab.svg" color="#000000">
    <link rel="shortcut icon" href="../images/favicon.ico">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="https://videopipe.github.io/images/mstile-144x144.png">
    <meta name="msapplication-config" content="https://videopipe.github.io/images/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="../assets/css/academicons.css" />
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); 
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
    <!-- end custom head snippets -->
</head>

<body>
    <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->
    <!-- 头部内容 -->
    <div style="background-image: url('images/top_no_text.png'); background-size: 100% 100%; height:200px; border=20px; min-width: 760px;"
        class="center">
        <div style="background-color: rgba(256,256,256,0.6); width: 100%; height: 100%; min-width: 760px;">
            <div style="width: 96%; height: 96%; margin: 2%; min-width: 760px" class="center">
                <p style="color:rgb(73, 78, 82); font-size: 28px; margin: 0px;"><b>VideoPipe@ ICPR2022</b></p>
                <p style="color:rgb(73, 78, 82); font-size: 32px; text-align:center; margin: 0px;"><b>Challenge on VideoPipe
                    <br>Real-World Video Understanding for Urban Pipe Inspection</b></p>
                <p style="color:rgb(73, 78, 82); font-size: 28px; margin: 0px; text-align: right;"><b>
                        Sunday 21th August 2022</b></p>
            </div>
        </div>
    </div>
    <style>
        .dropdown {
            position: relative;
            display: inline-block;
        }

        .dropdown-content {
            display: none;
            position: absolute;
            background-color: #f9f9f9;
            box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
        }

        .dropdown:hover .dropdown-content {
            display: block;
        }
    </style>
    <div class="masthead">
        <div class="masthead__inner-wrap">
            <!-- 菜单 -->
            <div class="masthead__menu">
                <nav id="site-nav" class="greedy-nav"> <button>
                        <div class="navicon"></div>
                    </button>
                    <ul class="visible-links clearfix">
                        <!-- 补充logo -->
                        <li class="masthead__menu-item masthead__menu-item--lg"><a href="index.html">
                                <image src="../images/logo.png" style="height:54px">
                            </a></li>
                        <li class="masthead__menu-item">
                            <div class="dropdown"> <span><a href="../index.html">Datasets</a></span>
                                <div class="dropdown-content">
                                    <p><a href="../qvpipe/index.html">QV-Pipe</a></p>
                                    <p><a href="../cctvpipe/index.html">CCTV-Pipe</a></p>
                                    <!-- <p><a href="kineticstps/index.html">Kinetics-TPS</a></p> -->
                                </div>
                            </div>
                        </li>
                        <li class="masthead__menu-item"><a href="../tracks/index.html">Tracks</a></li>
                        <li class="masthead__menu-item"><a href="../results/index.html">Challenge Results</a></li>
                        <!-- <li class="masthead__menu-item"><a href="importantdates/index.html">Important Dates</a></li> -->
                        <li class="masthead__menu-item"><a href="../organizers/index.html">Organizers</a></li>
                        <!-- <li class="masthead__menu-item"><a href="../speakers/index.html">Invited Speakers</a></li> -->
                        <li class="masthead__menu-item"><a href="../program/index.html">Program Schedule</a></li>
                    </ul>
                    <ul class="hidden-links hidden"></ul>
                </nav>
            </div><!-- 菜单 end -->
        </div>
    </div>
    <div id="main" role="main">
        <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
            <meta itemprop="headline" content="FineAction Dataset">
            <div class="page__inner-wrap">
                <header>
                    <h1 class="page__title" itemprop="headline">QV-Pipe Dataset</h1>
                </header>
                <section class="page__content" itemprop="text">
                    <!-- Main -->
                    <!-- <p style="margin-top:3px; margin-bottom:12px"> FineAction: A Fine-Grained Video Dataset for Temporal
                        Action Localization<br> [<a href="https://arxiv.org/abs/2105.11107">paper</a>]</p>
                    <p align="center" style="margin-top:12px"> <a href="mailto:yi.liu1@siat.ac.cn"><i
                                class="fas fa-envelope-open-text"></i></a>&nbsp <a href="https://www.yiliu.me/">Yi
                            Liu</a>&nbsp&nbsp <a href="mailto:lmwang.nju@gmail.com"><i
                                class="fas fa-envelope-open-text"></i></a>&nbsp <a
                            href="http://wanglimin.github.io">Limin Wang</a>&nbsp&nbsp <a
                            href="mailto:xiao.ma@siat.ac.cn"><i class="fas fa-envelope-open-text"></i></a>&nbsp <a
                            href=" https://hypnosx.github.io/Atopos.github.io">Xiao Ma</a>&nbsp&nbsp <a
                            href="mailto:yl.wang@siat.ac.cn"><i class="fas fa-envelope-open-text"></i></a>&nbsp <a
                            href="https://scholar.google.com/citations?hl=zh-CN&user=hD948dkAAAAJ">Yali
                            Wang</a>&nbsp&nbsp <a href="mailto:yu.qiao@siat.ac.cn"><i
                                class="fas fa-envelope-open-text"></i></a>&nbsp <a
                            href="http://mmlab.siat.ac.cn/yuqiao">Yu Qiao</a>&nbsp&nbsp</p>
                    <p align="center"> <a href="http://mmlab.siat.ac.cn">MMLAB @ Shenzhen Institute of Advanced
                            Technology</a></p>
                    <p align="center"> <a href="http://mcg.nju.edu.cn/en/index.html">MCG Group @ Nanjing University</a>
                    </p> -->
                    <div class="box">
                        <!-- <center> <span class="image fit"> <img src='../images/QV-Pipe Dataset.png'> </span> </center> -->
                        <!-- <span class="image fit"> <img src="/images/fineaction/show1.png" alt="" /> </span> <span class="image fit"> <img src="/images/fineaction/show2.png" alt="" /> </span> -->
                        <!--<p style="text-align:justify; text-justify:inter-ideograph;"><small>The 25fps tubelets of bounding boxes and fine-grained action category annotations in the sample frames of <i>MultiSports</i> dataset. Multiple concurrent action situations frequently appear in <i>MultiSports</i> with many starting and ending points in the long untrimmed video clips. The frames are cropped and sampled by stride 5 or 7 for visualization propose. Tubes with the same color represent the same person.</small></p>-->
                        <hr />
                        <header>
                            <h3>Abstract</h3>
                        </header>
                        <p style="text-align:justify; text-justify:inter-ideograph;">We have carefully collected and annotated 
                            two new industrial video datasets, namely QV-Pipe and CCTV-Pipe, for video understanding in urban pipe 
                            inspection. Specifically,<b><i> QV-Pipe is used for video defect classification (Task1) and CCTV-Pipe 
                            is used for temporal defect localization (Task 2).</i></b></p>
                        <p style="text-align:justify; text-justify:inter-ideograph;">Note that, all the participants are required 
                            to sign a copyright form for academic research, before getting our datasets. Besides, the datasets are 
                            based on the real-world pipe networks. Hence, we have deleted the information of street, city 
                            and any other about privacy in our datasets.</p>
                        <!--<header><h3>Demo Video</h3><p>Please choose "1080P" for better experience.</p></header><p align="center"><iframe width="600" height="320" src="https://www.youtube.com/embed/uGjvKYWZ5Ww" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>-->
                        <!--<header><h3>Hierarchy of Action Category</h3></header><span class="image fit"><img src="/images/ms_hier.png" alt=""/></span><p style="text-align:justify; text-justify:inter-ideograph;"> The action vocabulary hierarchy and annotator interface of the <i>MultiSports</i> dataset. Our <i>MultiSports</i> has a two-level hierarchy of action vocabularies, where the actions of each sport are fine-grained.</p>-->
                        <header>
                            <h3>Data Collection & Annotation</h3>
                        </header>
                        <p style="text-align:justify; text-justify:inter-ideograph;"> The QV-Pipe dataset consists of 1 normal class and 
                            16 defect classes and 13k videos, which are collected from real-world urban pipes and annotated by professional 
                            engineers. The total duration of all videos exceeds 73 hours. Because the pipe situation is complex, multiple 
                            defects often appear at the same time, so each video is annotated by multiple labels. To obtain accurate 
                            annotations of defect instances, professional engineers are asked to check all the videos multiple rounds 
                            with cross validation. Given a QV video, our goal is to predict multiple labels of pipe defects in this video. 
                            Examples of QV-Pipe are shown in Figure 1.</p>
                        <center> <span class="image fit"> <img src='../images/QV-Pipe Dataset.png'> </span> 
                        <p>Figure 1. Examples of Our QV-Pipe Dataset</p></center>
                        <!-- <ol>
                            <li> Complete organizational taxonomy behind FineAction. <span class="image fit"><img
                                        src="../images/fineaction/category.png" /></span></li>
                        </ol> -->
                        <header>
                            <h3>Data Comparison</h3>
                        </header>
                        <p style="text-align:justify; text-justify:inter-ideograph;"> The QV-Pipe video duration ranges from 0.7 seconds to 385.2 seconds. 
                            Each video is annotated by 1 to 5 categories. On average, each video has the duration of 20.7 seconds and 1.4 labels. 
                            The 13k videos are divided into train set, validation set and test set according to the ratio of 2:1:1. As shown in 
                            Figure 2, the data exhibits the natural long-tailed distribution.</p>
                        <center> <span class="image fit"> <img src='../images/Data Distribution of QV-Pipe.png'> </span> 
                            <p>Figure 2. Data Distribution of QV-Pipe</p></center>
                        
                        <p style="text-align:justify; text-justify:inter-ideograph;"> Moreover, we compare it with the existing benchmarks in video 
                            anomaly detection. As shown in Table 1, our QV-Pipe dataset shows the following distinct characteristics. First, compared 
                            to the existing benchmarks, our QV-Pipe is large scale. Second, each video in our QV-Pipe contains multiple anomaly 
                            categories, and these categories are fine-grained. Finally, the previous datasets mainly works on human. Alternatively, 
                            the domain shift is large for urban pipe inspection. Hence, our QV-Pipe brings new challenges and opportunities to 
                            understand video content for anomaly detection and beyond.</p>
                        <center><p>Table 1. Video Anomaly Detection Benchmark Comparison</p>
                             <span class="image fit"> <img src='../images/Video Anomaly Detection Benchmark Comparison.png'> </span> 
                            </center>

                        <!-- <ol>
                            <li> Comparison with Related Benchmarks. Our FineAction is unique due to its fine-grained
                                action classes, multi-label and dense annotations, relatively large-scale capacity, and
                                rich action diversity. <span class="image fit"><img
                                        src="../images/fineaction/tab1.png" /></span></li>
                            <li> Number of instances per category. We plot the instance distribution of all the
                                bottom-level categories in each top-level category. All the plots exhibit the natural
                                long-tailed distribution. <span class="image fit"><img
                                        src="../images/fineaction/fig1.png" /></span></li>
                        </ol> -->
                        <!--<header><h3>Dataset Properties</h3></header><p style="text-align:justify; text-justify:inter-ideograph;"> Our <i>MultiSports</i> contains 66 fine-grained action categories from four different sports, selected from 247 competition records. The records are manually cut into 800 clips per sport to keep the balance of data size between sports, where we discard intervals with only background scenes, such as award, and select the highlights of competitions as video clips for action localization.</p><ol><li> Overall comparison of statistics between existing action localization datasets and our <i>MultiSports</i> v1.0. (* only train and val sets' ground-truths are available, † number of person tracklets, each of which has one or more action labels, ‡ 1fps action annotations have no clear action boundaries) <span class="image fit"><img src="/images/fineaction/tab1.png" alt="comparison with other dataset"/></span></li><li> Overall comparison of statistics between existing action localization datasets and our <i>MultiSports</i> v1.0. (* only train and val sets' ground-truths are available, † number of person tracklets, each of which has one or more action labels, ‡ 1fps action annotations have no clear action boundaries) <span class="image fit"><img src="/images/fineaction/pic1.png" alt="comparison with other dataset"/></span></li><li> Statistics of each action class's data size in <i>MultiSports</i> sorted by descending order with 4 colors indicating 4 different sports. For actions in the different sports sharing the same name, we add the name of sports after them. The natural long-tailed distribution of action categories raises new challenges for action localization models. <span class="image fit"><img src="/images/fineaction/pic2.png" alt="number of instances"/></span></li></ol>-->
                        <!-- <header>
                            <h3>Experiment Results</h3>
                        </header>
                        <ol>
                            <li> Comparison of the state-of-the-art methods on the validation set of FineAction. Left:
                                evaluation on action proposal generation, in terms of AR@AN. Right : evaluation on
                                action detection, in terms of mAP at IoU thresholds from 0.5 to 0.95. <span
                                    class="image fit"><img src="../images/fineaction/exp1.png" /></span></li>
                            <li> Error analysis on FineAction. (a) Left : the error distribution over the number of
                                predictions per video. G means the number of Ground-Truth instances. Right: the impact
                                of error types, measured by the improvement gained from resolving a particular type of
                                error. (b) Visualization of typical failure cases on FineAction. <span
                                    class="image fit"><img src="../images/fineaction/exp2.png" /></span></li>
                        </ol> -->
                        <header>
                            <h3>Download</h3>
                            <p>Please refer to the <a
                                    href="https://competitions.codalab.org/competitions/32363">competition page</a> for
                                more information.</p>
                            <!--<p > <a href="https://pan.baidu.com/s/1LiCXqqhsJAOf05oyOh_h6g">Raw_video</a> Access Code: e0e2 <br></p><p > <a href="https://pan.baidu.com/s/11DGhaS5Agtk9Ma_tSo9TaA">i3d feature</a> Access Code: bl7y <br></p><p > <a href="https://pan.baidu.com/s/15JONgemgCKa2Y8747wAVoA">i3d feature-100</a> Access Code: w0rx <br></p>-->
                        </header>
                        <header>
                            <h3>Reference</h3>
                        </header>
                        <ol>
                            <li style="text-align:justify; text-justify:inter-ideograph;"> Li, Weixin, Vijay Mahadevan, and Nuno Vasconcelos. "Anomaly detection and localization in crowded scenes." 
                                IEEE transactions on pattern analysis and machine intelligence 36.1 (2013): 18-32.</li>
                            <li style="text-align:justify; text-justify:inter-ideograph;"> Adam, Amit, et al. "Robust real-time unusual event detection using multiple fixed-location monitors." 
                                IEEE transactions on pattern analysis and machine intelligence 30.3 (2008): 555-560.</li>
                            <li style="text-align:justify; text-justify:inter-ideograph;">Lu, Cewu, Jianping Shi, and Jiaya Jia. "Abnormal event detection at 150 fps in matlab." 
                                Proceedings of the IEEE international conference on computer vision. 2013.</li>
                            <li style="text-align:justify; text-justify:inter-ideograph;">Raghavendra, R., A. D. Bue, and M. Cristani. "Unusual crowd activity dataset of University of Minnesota." (2006).</li>
                            <li style="text-align:justify; text-justify:inter-ideograph;">Sultani, Waqas, Chen Chen, and Mubarak Shah. "Real-world anomaly detection in surveillance videos." 
                                Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</li>
                        </ol>
                    </div>
                </section>
                <footer class="page__meta"></footer>
            </div>
        </article>
    </div>
    <div class="page__footer">
        <footer>
            <!-- start custom footer snippets -->
            <!-- end custom footer snippets -->
            <div class="page__footer-follow">
                <ul class="social-icons"></ul>
            </div>
            <div class="page__footer-copyright">&copy; 2022 VideoPipe. Powered by <a href="http://jekyllrb.com"
                    rel="nofollow">Jekyll</a> &amp; <a
                    href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a
                    href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal
                    Mistakes</a>.</div>
        </footer>
    </div>
    <script src="../assets/js/main.min.js"></script>
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
        ga('create', '', 'auto');
        ga('send', 'pageview');
    </script> <!-- Jekyll Ideal Image Slider Include -->
    <!-- https://github.com/jekylltools/jekyll-ideal-image-slider-include -->
    <!-- v1.8 -->
</body>

</html>